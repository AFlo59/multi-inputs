{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (1.67.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.3)\n",
      "Requirement already satisfied: optree in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: namex in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: transformers in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (4.46.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (0.26.1)\n",
      "Requirement already satisfied: requests in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: filelock in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: pandas in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install transformers\n",
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV chargé avec succès.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file_path = './Flipkart/flipkart_com-ecommerce_sample_1050.csv'\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"CSV chargé avec succès.\")\n",
    "else:\n",
    "    print(f\"Erreur : Le fichier n'existe pas à l'emplacement {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajoutez le chemin des images et préparez les labels de catégories\n",
    "data['image_path'] = data['image'].apply(lambda x: f'./Flipkart/Images/{x}')\n",
    "data['category'] = data['product_category_tree'].apply(lambda x: x.split(\">>\")[0].replace(\"[\", \"\").replace(\"]\", \"\").replace('\"', '').strip())\n",
    "categories = data['category'].unique().tolist()\n",
    "category_to_index = {cat: idx for idx, cat in enumerate(categories)}\n",
    "data['category_id'] = data['category'].map(category_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Home Furnishing',\n",
       " 'Baby Care',\n",
       " 'Watches',\n",
       " 'Home Decor & Festive Needs',\n",
       " 'Kitchen & Dining',\n",
       " 'Beauty and Personal Care',\n",
       " 'Computers']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des données\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_text = data['description'].fillna(\"\")\n",
    "X_image = data['image_path']\n",
    "y = data['category_id']\n",
    "X_train_text, X_test_text, X_train_image, X_test_image, y_train, y_test = train_test_split(X_text, X_image, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 7s/step - accuracy: 0.1828 - loss: 1.9992 - val_accuracy: 0.2810 - val_loss: 1.9344\n",
      "Epoch 2/3\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 7s/step - accuracy: 0.2674 - loss: 1.9398 - val_accuracy: 0.3571 - val_loss: 1.9035\n",
      "Epoch 3/3\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 7s/step - accuracy: 0.3154 - loss: 1.9226 - val_accuracy: 0.3762 - val_loss: 1.8753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x798638461420>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger le tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Convertir X_train_text et X_test_text en listes de chaînes pour le tokenizer\n",
    "X_train_text = X_train_text.tolist()\n",
    "X_test_text = X_test_text.tolist()\n",
    "\n",
    "# Ensuite, encodez les descriptions de texte\n",
    "X_train_encoded = tokenizer(X_train_text, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "X_test_encoded = tokenizer(X_test_text, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "\n",
    "\n",
    "# Charger le modèle DistilBERT sans tête de classification\n",
    "base_model = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Ajout de la couche de classification\n",
    "class TextClassificationModel(Model):\n",
    "    def __init__(self, base_model, num_classes):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.classifier = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.base_model(inputs)\n",
    "        pooled_output = tf.reduce_mean(outputs.last_hidden_state, axis=1)\n",
    "        return self.classifier(pooled_output)\n",
    "\n",
    "# Initialiser le modèle de classification de texte\n",
    "text_model = TextClassificationModel(base_model, num_classes=len(categories))\n",
    "\n",
    "# Compiler le modèle\n",
    "text_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5), \n",
    "                   loss=\"sparse_categorical_crossentropy\", \n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraîner le modèle\n",
    "text_model.fit(\n",
    "    {\"input_ids\": X_train_encoded[\"input_ids\"], \"attention_mask\": X_train_encoded[\"attention_mask\"]},\n",
    "    y_train,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    "    validation_data=(\n",
    "        {\"input_ids\": X_test_encoded[\"input_ids\"], \"attention_mask\": X_test_encoded[\"attention_mask\"]}, \n",
    "        y_test\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle de texte\n",
    "text_model.save('text_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 3s/step - accuracy: 0.3296 - loss: 1.7591 - val_accuracy: 0.1810 - val_loss: 1.9994\n",
      "Epoch 2/3\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 3s/step - accuracy: 0.7649 - loss: 0.9119 - val_accuracy: 0.1810 - val_loss: 2.0215\n",
      "Epoch 3/3\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 3s/step - accuracy: 0.8546 - loss: 0.5696 - val_accuracy: 0.1857 - val_loss: 1.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x798659785ae0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np  # Importation de numpy\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Prétraitement des images\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "# Chargement des images\n",
    "X_train_image_processed = np.array([load_and_preprocess_image(img_path) for img_path in X_train_image])\n",
    "X_test_image_processed = np.array([load_and_preprocess_image(img_path) for img_path in X_test_image])\n",
    "\n",
    "# Modèle de classification d'image\n",
    "base_model = EfficientNetB0(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "output = Dense(len(categories), activation=\"softmax\")(x)\n",
    "image_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "image_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraînement du modèle\n",
    "image_model.fit(X_train_image_processed, y_train, batch_size=16, epochs=3, validation_data=(X_test_image_processed, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle d'image\n",
    "image_model.save('image_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_distil_bert_model_2' (type TFDistilBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_distil_bert_model_2' (type TFDistilBertModel):\n  • input_ids=<KerasTensor shape=(None, None), dtype=int32, sparse=False, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, None), dtype=int32, sparse=False, name=attention_mask>\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m text_mask \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m text_model \u001b[38;5;241m=\u001b[39m TFDistilBertModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m text_features \u001b[38;5;241m=\u001b[39m \u001b[43mtext_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Entrée pour l'image\u001b[39;00m\n\u001b[1;32m     13\u001b[0m image_input \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:436\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m--> 436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m \u001b[43minput_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args_and_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m~/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:513\u001b[0m, in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m         output[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(main_input, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(main_input):\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;66;03m# EagerTensors don't allow to use the .name property so we check for a real Tensor\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_distil_bert_model_2' (type TFDistilBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_distil_bert_model_2' (type TFDistilBertModel):\n  • input_ids=<KerasTensor shape=(None, None), dtype=int32, sparse=False, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, None), dtype=int32, sparse=False, name=attention_mask>\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from transformers import TFDistilBertModel\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "# Entrée pour le texte\n",
    "text_input = Input(shape=(None,), dtype=tf.int32, name=\"input_ids\")\n",
    "text_mask = Input(shape=(None,), dtype=tf.int32, name=\"attention_mask\")\n",
    "text_model = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "text_features = text_model(text_input, attention_mask=text_mask).last_hidden_state[:, 0, :]\n",
    "\n",
    "# Entrée pour l'image\n",
    "image_input = Input(shape=(224, 224, 3), name=\"image_input\")\n",
    "base_image_model = EfficientNetB0(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
    "image_features = GlobalAveragePooling2D()(base_image_model(image_input))\n",
    "\n",
    "# Fusion des deux sorties\n",
    "combined_features = Concatenate()([text_features, image_features])\n",
    "output = Dense(len(categories), activation=\"softmax\")(combined_features)\n",
    "\n",
    "# Modèle multi-input\n",
    "multi_input_model = Model(inputs=[text_input, text_mask, image_input], outputs=output)\n",
    "\n",
    "# Compilation du modèle\n",
    "multi_input_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraînement du modèle\n",
    "multi_input_model.fit(\n",
    "    [train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"], X_train_image_processed],\n",
    "    y_train,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    "    validation_data=([test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"], X_test_image_processed], y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données d'entrée\n",
    "def predict_text_category(description):\n",
    "    inputs = tokenizer(description, return_tensors=\"tf\", padding=\"max_length\", truncation=True)\n",
    "    outputs = text_model(inputs)\n",
    "    prediction = tf.argmax(outputs, axis=1).numpy()[0]\n",
    "    return categories[prediction]\n",
    "\n",
    "# Exemple de prédiction\n",
    "description_test = \"A powerful all-in-one computer with last generation components\"\n",
    "print(\"Predicted Category:\", predict_text_category(description_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_image_from_url(url):\n",
    "    # Télécharger l'image depuis l'URL\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Ouvrir l'image avec PIL et la convertir au format attendu par le modèle\n",
    "    image = Image.open(response.raw).convert(\"RGB\")\n",
    "    image = image.resize((224, 224))  # Redimensionner l'image\n",
    "    image = np.array(image) / 255.0   # Normaliser les pixels entre 0 et 1\n",
    "    return image\n",
    "\n",
    "def predict_image_category_from_url(url):\n",
    "    # Charger et prétraiter l'image depuis l'URL\n",
    "    image = load_and_preprocess_image_from_url(url)\n",
    "    image = tf.expand_dims(image, axis=0)  # Ajouter une dimension pour le batch\n",
    "\n",
    "    # Prédire la catégorie\n",
    "    prediction = tf.argmax(image_model.predict(image), axis=1).numpy()[0]\n",
    "    return categories[prediction]\n",
    "\n",
    "# URL de l'image\n",
    "image_url = \"https://cdn.pixabay.com/photo/2020/10/21/18/07/laptop-5673901_1280.jpg\"\n",
    "print(\"Predicted Category:\", predict_image_category_from_url(image_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Charger le tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def load_and_preprocess_image_from_url(url):\n",
    "    # Télécharger l'image depuis l'URL\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Ouvrir l'image avec PIL et la convertir au format attendu par le modèle\n",
    "    image = Image.open(response.raw).convert(\"RGB\")\n",
    "    image = image.resize((224, 224))  # Redimensionner l'image\n",
    "    image = np.array(image) / 255.0   # Normaliser les pixels entre 0 et 1\n",
    "    return image\n",
    "\n",
    "def predict_multi_input(description, image_url):\n",
    "    # Prétraitement de la description\n",
    "    text_inputs = tokenizer(description, return_tensors=\"tf\", padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    # Charger et prétraiter l'image depuis l'URL\n",
    "    image = load_and_preprocess_image_from_url(image_url)\n",
    "    image = tf.expand_dims(image, axis=0)  # Ajouter une dimension pour le batch\n",
    "\n",
    "    # Prédire la catégorie\n",
    "    prediction = tf.argmax(\n",
    "        multi_input_model.predict(\n",
    "            {\"input_ids\": text_inputs[\"input_ids\"], \"attention_mask\": text_inputs[\"attention_mask\"], \"image_input\": image}\n",
    "        ), axis=1\n",
    "    ).numpy()[0]\n",
    "    return categories[prediction]\n",
    "\n",
    "# Exemple d'URL de l'image et description\n",
    "description_test = \"TV support table wood style rétro\"\n",
    "image_url = \"https://cdn1.hellin.fr/26695-zoom_default/meuble-tv-retro-en-bois-2-niches-2-portes-l180-mallet.jpg\"\n",
    "print(\"Predicted Category:\", predict_multi_input(description_test, image_url))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des poids du modèle de texte\n",
    "text_model.save_weights('/content/text_model_weights')\n",
    "\n",
    "# Sauvegarde des poids du modèle d'image\n",
    "image_model.save_weights('/content/image_model_weights')\n",
    "\n",
    "# Sauvegarde des poids du modèle multi-input\n",
    "multi_input_model.save_weights('/content/multi_input_model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizer\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Recréer la structure du modèle de texte\n",
    "class TextClassificationModel(Model):\n",
    "    def __init__(self, base_model, num_classes):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.classifier = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.base_model(inputs)\n",
    "        pooled_output = tf.reduce_mean(outputs.last_hidden_state, axis=1)\n",
    "        return self.classifier(pooled_output)\n",
    "\n",
    "# Instancier et charger les poids\n",
    "base_model = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "text_model = TextClassificationModel(base_model, num_classes=len(categories))\n",
    "text_model.load_weights('path/to/text_model_weights')\n",
    "\n",
    "# Procédez de même pour le modèle d'image et le modèle multi-input\n",
    "# Exemple pour le modèle d'image\n",
    "image_model = ...  # recréez la structure du modèle d'image\n",
    "image_model.load_weights('path/to/image_model_weights')\n",
    "\n",
    "# Exemple pour le modèle multi-input\n",
    "multi_input_model = ...  # recréez la structure du modèle multi-input\n",
    "multi_input_model.load_weights('path/to/multi_input_model_weights')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
