{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: packaging in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (1.67.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: setuptools in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: optree in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: rich in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.3)\n",
      "Requirement already satisfied: namex in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: transformers in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (4.46.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: requests in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: filelock in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (0.26.1)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: pandas in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install transformers\n",
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Concatenate, Lambda, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV chargé avec succès.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file_path = './Flipkart/flipkart_com-ecommerce_sample_1050.csv'\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"CSV chargé avec succès.\")\n",
    "else:\n",
    "    print(f\"Erreur : Le fichier n'existe pas à l'emplacement {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajoutez le chemin des images et préparez les labels de catégories\n",
    "data['image_path'] = data['image'].apply(lambda x: f'./Flipkart/Images/{x}')\n",
    "data['category'] = data['product_category_tree'].apply(lambda x: x.split(\">>\")[0].replace(\"[\", \"\").replace(\"]\", \"\").replace('\"', '').strip())\n",
    "categories = data['category'].unique().tolist()\n",
    "category_to_index = {cat: idx for idx, cat in enumerate(categories)}\n",
    "data['category_id'] = data['category'].map(category_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Home Furnishing',\n",
       " 'Baby Care',\n",
       " 'Watches',\n",
       " 'Home Decor & Festive Needs',\n",
       " 'Kitchen & Dining',\n",
       " 'Beauty and Personal Care',\n",
       " 'Computers']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ./Flipkart/Images/55b85ea15a1536d46b7190ad6fff...\n",
       "1       ./Flipkart/Images/7b72c92c2f6c40268628ec5f14c6...\n",
       "2       ./Flipkart/Images/64d5d4a258243731dc7bbb1eef49...\n",
       "3       ./Flipkart/Images/d4684dcdc759dd9cdf41504698d7...\n",
       "4       ./Flipkart/Images/6325b6870c54cd47be6ebfbffa62...\n",
       "                              ...                        \n",
       "1045    ./Flipkart/Images/958f54f4c46b53c8a0a9b8167d91...\n",
       "1046    ./Flipkart/Images/fd6cbcc22efb6b761bd564c28928...\n",
       "1047    ./Flipkart/Images/5912e037d12774bb73a2048f35a0...\n",
       "1048    ./Flipkart/Images/c3edc504d1b4f0ba6224fa53a43a...\n",
       "1049    ./Flipkart/Images/f2f027ad6a6df617c9f125173da7...\n",
       "Name: image_path, Length: 1050, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['image_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des données\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_text = data['description'].fillna(\"\")\n",
    "X_image = data['image_path']\n",
    "y = data['category_id']\n",
    "X_train_text, X_test_text, X_train_image, X_test_image, y_train, y_test = train_test_split(X_text, X_image, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1730294561.105021    8100 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-10-30 14:22:41.786909: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-10-30 14:22:41.919334: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-10-30 14:22:41.942457: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-10-30 14:22:42.915939: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 14:22:50.677783: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 201326592 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 7s/step - accuracy: 0.1566 - loss: 1.9612 - val_accuracy: 0.1667 - val_loss: 1.9287\n",
      "Epoch 2/3\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 7s/step - accuracy: 0.1783 - loss: 1.9182 - val_accuracy: 0.1810 - val_loss: 1.8968\n",
      "Epoch 3/3\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 8s/step - accuracy: 0.2229 - loss: 1.8916 - val_accuracy: 0.2429 - val_loss: 1.8686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7d78d7a7af80>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger le tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Convertir X_train_text et X_test_text en listes de chaînes pour le tokenizer\n",
    "X_train_text = X_train_text.tolist()\n",
    "X_test_text = X_test_text.tolist()\n",
    "\n",
    "# Ensuite, encodez les descriptions de texte\n",
    "X_train_encoded = tokenizer(X_train_text, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "X_test_encoded = tokenizer(X_test_text, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "\n",
    "\n",
    "# Charger le modèle DistilBERT sans tête de classification\n",
    "base_model = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Ajout de la couche de classification\n",
    "class TextClassificationModel(Model):\n",
    "    def __init__(self, base_model, num_classes):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.classifier = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.base_model(inputs)\n",
    "        pooled_output = tf.reduce_mean(outputs.last_hidden_state, axis=1)\n",
    "        return self.classifier(pooled_output)\n",
    "\n",
    "# Initialiser le modèle de classification de texte\n",
    "text_model = TextClassificationModel(base_model, num_classes=len(categories))\n",
    "\n",
    "# Compiler le modèle\n",
    "text_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5), \n",
    "                   loss=\"sparse_categorical_crossentropy\", \n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraîner le modèle\n",
    "text_model.fit(\n",
    "    {\"input_ids\": X_train_encoded[\"input_ids\"], \"attention_mask\": X_train_encoded[\"attention_mask\"]},\n",
    "    y_train,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    "    validation_data=(\n",
    "        {\"input_ids\": X_test_encoded[\"input_ids\"], \"attention_mask\": X_test_encoded[\"attention_mask\"]}, \n",
    "        y_test\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 3s/step - accuracy: 0.3296 - loss: 1.7591 - val_accuracy: 0.1810 - val_loss: 1.9994\n",
      "Epoch 2/3\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 3s/step - accuracy: 0.7649 - loss: 0.9119 - val_accuracy: 0.1810 - val_loss: 2.0215\n",
      "Epoch 3/3\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 3s/step - accuracy: 0.8546 - loss: 0.5696 - val_accuracy: 0.1857 - val_loss: 1.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x798659785ae0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np  # Importation de numpy\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Prétraitement des images\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "# Chargement des images\n",
    "X_train_image_processed = np.array([load_and_preprocess_image(img_path) for img_path in X_train_image])\n",
    "X_test_image_processed = np.array([load_and_preprocess_image(img_path) for img_path in X_test_image])\n",
    "\n",
    "# Modèle de classification d'image\n",
    "base_model = EfficientNetB0(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "output = Dense(len(categories), activation=\"softmax\")(x)\n",
    "image_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "image_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraînement du modèle\n",
    "image_model.fit(X_train_image_processed, y_train, batch_size=16, epochs=3, validation_data=(X_test_image_processed, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 14:17:31.267279: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-30 14:17:31.413994: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-30 14:17:31.531861: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730294251.678590    8100 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730294251.720811    8100 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-30 14:17:32.025222: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/utilisateur/Bureau/week2/multi-inputs/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EfficientNetB0\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Entrée pour le texte\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m text_input \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m,), dtype\u001b[38;5;241m=\u001b[39m\u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m text_mask \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m text_model \u001b[38;5;241m=\u001b[39m TFDistilBertModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from transformers import TFDistilBertModel\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "# Entrée pour le texte\n",
    "text_input = Input(shape=(None,), dtype=tf.int32, name=\"input_ids\")\n",
    "text_mask = Input(shape=(None,), dtype=tf.int32, name=\"attention_mask\")\n",
    "text_model = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "text_features = text_model(text_input, attention_mask=text_mask).last_hidden_state[:, 0, :]\n",
    "\n",
    "# Entrée pour l'image\n",
    "image_input = Input(shape=(224, 224, 3), name=\"image_input\")\n",
    "base_image_model = EfficientNetB0(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
    "image_features = GlobalAveragePooling2D()(base_image_model(image_input))\n",
    "\n",
    "# Fusion des deux sorties\n",
    "combined_features = Concatenate()([text_features, image_features])\n",
    "output = Dense(len(categories), activation=\"softmax\")(combined_features)\n",
    "\n",
    "# Modèle multi-input\n",
    "multi_input_model = Model(inputs=[text_input, text_mask, image_input], outputs=output)\n",
    "\n",
    "# Compilation du modèle\n",
    "multi_input_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraînement du modèle\n",
    "multi_input_model.fit(\n",
    "    [train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"], X_train_image_processed],\n",
    "    y_train,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    "    validation_data=([test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"], X_test_image_processed], y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Exemple de prédiction\u001b[39;00m\n\u001b[1;32m      9\u001b[0m description_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA powerful all-in-one computer with last generation components\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Category:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mpredict_text_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescription_test\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36mpredict_text_category\u001b[0;34m(description)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_text_category\u001b[39m(description):\n\u001b[0;32m----> 3\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(description, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m text_model(inputs)\n\u001b[1;32m      5\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(outputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Préparer les données d'entrée\n",
    "def predict_text_category(description):\n",
    "    inputs = tokenizer(description, return_tensors=\"tf\", padding=\"max_length\", truncation=True)\n",
    "    outputs = text_model(inputs)\n",
    "    prediction = tf.argmax(outputs, axis=1).numpy()[0]\n",
    "    return categories[prediction]\n",
    "\n",
    "# Exemple de prédiction\n",
    "description_test = \"A powerful all-in-one computer with last generation components\"\n",
    "print(\"Predicted Category:\", predict_text_category(description_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_image_from_url(url):\n",
    "    # Télécharger l'image depuis l'URL\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Ouvrir l'image avec PIL et la convertir au format attendu par le modèle\n",
    "    image = Image.open(response.raw).convert(\"RGB\")\n",
    "    image = image.resize((224, 224))  # Redimensionner l'image\n",
    "    image = np.array(image) / 255.0   # Normaliser les pixels entre 0 et 1\n",
    "    return image\n",
    "\n",
    "def predict_image_category_from_url(url):\n",
    "    # Charger et prétraiter l'image depuis l'URL\n",
    "    image = load_and_preprocess_image_from_url(url)\n",
    "    image = tf.expand_dims(image, axis=0)  # Ajouter une dimension pour le batch\n",
    "\n",
    "    # Prédire la catégorie\n",
    "    prediction = tf.argmax(image_model.predict(image), axis=1).numpy()[0]\n",
    "    return categories[prediction]\n",
    "\n",
    "# URL de l'image\n",
    "image_url = \"https://cdn.pixabay.com/photo/2020/10/21/18/07/laptop-5673901_1280.jpg\"\n",
    "print(\"Predicted Category:\", predict_image_category_from_url(image_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Charger le tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def load_and_preprocess_image_from_url(url):\n",
    "    # Télécharger l'image depuis l'URL\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Ouvrir l'image avec PIL et la convertir au format attendu par le modèle\n",
    "    image = Image.open(response.raw).convert(\"RGB\")\n",
    "    image = image.resize((224, 224))  # Redimensionner l'image\n",
    "    image = np.array(image) / 255.0   # Normaliser les pixels entre 0 et 1\n",
    "    return image\n",
    "\n",
    "def predict_multi_input(description, image_url):\n",
    "    # Prétraitement de la description\n",
    "    text_inputs = tokenizer(description, return_tensors=\"tf\", padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    # Charger et prétraiter l'image depuis l'URL\n",
    "    image = load_and_preprocess_image_from_url(image_url)\n",
    "    image = tf.expand_dims(image, axis=0)  # Ajouter une dimension pour le batch\n",
    "\n",
    "    # Prédire la catégorie\n",
    "    prediction = tf.argmax(\n",
    "        multi_input_model.predict(\n",
    "            {\"input_ids\": text_inputs[\"input_ids\"], \"attention_mask\": text_inputs[\"attention_mask\"], \"image_input\": image}\n",
    "        ), axis=1\n",
    "    ).numpy()[0]\n",
    "    return categories[prediction]\n",
    "\n",
    "# Exemple d'URL de l'image et description\n",
    "description_test = \"TV support table wood style rétro\"\n",
    "image_url = \"https://cdn1.hellin.fr/26695-zoom_default/meuble-tv-retro-en-bois-2-niches-2-portes-l180-mallet.jpg\"\n",
    "print(\"Predicted Category:\", predict_multi_input(description_test, image_url))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des poids du modèle de texte\n",
    "text_model.save_weights('/content/text_model_weights')\n",
    "\n",
    "# Sauvegarde des poids du modèle d'image\n",
    "image_model.save_weights('/content/image_model_weights')\n",
    "\n",
    "# Sauvegarde des poids du modèle multi-input\n",
    "multi_input_model.save_weights('/content/multi_input_model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizer\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Recréer la structure du modèle de texte\n",
    "class TextClassificationModel(Model):\n",
    "    def __init__(self, base_model, num_classes):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.classifier = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.base_model(inputs)\n",
    "        pooled_output = tf.reduce_mean(outputs.last_hidden_state, axis=1)\n",
    "        return self.classifier(pooled_output)\n",
    "\n",
    "# Instancier et charger les poids\n",
    "base_model = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "text_model = TextClassificationModel(base_model, num_classes=len(categories))\n",
    "text_model.load_weights('path/to/text_model_weights')\n",
    "\n",
    "# Procédez de même pour le modèle d'image et le modèle multi-input\n",
    "# Exemple pour le modèle d'image\n",
    "image_model = ...  # recréez la structure du modèle d'image\n",
    "image_model.load_weights('path/to/image_model_weights')\n",
    "\n",
    "# Exemple pour le modèle multi-input\n",
    "multi_input_model = ...  # recréez la structure du modèle multi-input\n",
    "multi_input_model.load_weights('path/to/multi_input_model_weights')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
